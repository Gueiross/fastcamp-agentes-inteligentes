{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a781a1b-ec0b-48f1-abcd-075ebd370954",
   "metadata": {},
   "source": [
    "# Adicionando requisitos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6dc2f5-c331-40ff-9263-5f5ea8c4cbb8",
   "metadata": {},
   "source": [
    "Nesta primeira parte do script, são importadas as bibliotecas necessárias e carregadas as variáveis de ambiente com load_dotenv(), isolando do codigo dados, como a chave a api do Groq. Em seguida, a biblioteca groq é importada, necessária para instanciar o cliente e permitir o uso do modelo de IA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ada54d9b-2fe5-4979-99ea-af57aade026c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c3b40c-67a5-4a0f-87b2-26c3faf320c8",
   "metadata": {},
   "source": [
    "# Criação de client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6031fb-7246-4c32-9410-8d22849a3410",
   "metadata": {},
   "source": [
    "Com a chave da API carregada nas variáveis de ambiente, é feito um teste para verificar a resposta do modelo a uma pergunta. Esse passo também ajuda a entender a estrutura dos objetos retornados pela API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f249664b-8226-402b-809b-84d4ba9092ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's natural language processing (NLP) landscape, and their importance can be seen in several aspects:\n",
      "\n",
      "1. **Real-time Applications**: Fast language models enable real-time applications such as chatbots, virtual assistants, and language translation systems to respond quickly and efficiently. This is particularly important in customer-facing applications where delayed responses can lead to frustration and a negative user experience.\n",
      "2. **Low-Latency Inference**: Fast language models can perform inference (i.e., make predictions) quickly, which is essential for applications that require rapid decision-making, such as sentiment analysis, entity recognition, and question answering.\n",
      "3. **Scalability**: Fast language models can handle large volumes of data and scale to meet the demands of big data and high-traffic applications. This is critical in industries like customer service, where handling a large volume of conversations simultaneously is essential.\n",
      "4. **Energy Efficiency**: Fast language models can reduce the computational resources required for NLP tasks, leading to energy efficiency and cost savings. This is particularly important for edge devices, mobile devices, and data centers where energy consumption is a concern.\n",
      "5. **Improved User Experience**: Fast language models can provide a more seamless and responsive user experience, enabling users to interact with language-based systems more naturally and efficiently.\n",
      "6. **Competitive Advantage**: In industries like customer service, fast language models can provide a competitive advantage by enabling companies to respond quickly and efficiently to customer inquiries, leading to improved customer satisfaction and loyalty.\n",
      "7. **Research and Development**: Fast language models can accelerate research and development in NLP by enabling researchers to experiment and iterate more quickly, leading to faster breakthroughs and advancements in the field.\n",
      "8. **Edge AI**: Fast language models are essential for edge AI applications, where models need to run on resource-constrained devices like smart home devices, autonomous vehicles, and wearables.\n",
      "9. **Real-time Analytics**: Fast language models can enable real-time analytics and insights, allowing businesses to respond quickly to changing market conditions, customer sentiment, and other factors.\n",
      "10. **Accessibility**: Fast language models can improve accessibility for people with disabilities, such as those who rely on speech-to-text systems or language translation tools.\n",
      "\n",
      "To achieve fast language models, researchers and developers employ various techniques, including:\n",
      "\n",
      "1. Model pruning and knowledge distillation\n",
      "2. Quantization and binarization\n",
      "3. Efficient neural network architectures\n",
      "4. Parallelization and distributed computing\n",
      "5. GPU acceleration and specialized hardware\n",
      "6. Caching and memoization\n",
      "7. Approximation algorithms and sampling techniques\n",
      "\n",
      "By leveraging these techniques, fast language models can unlock new possibilities in NLP and have a significant impact on various industries and applications.\n"
     ]
    }
   ],
   "source": [
    "client = Groq(api_key=os.environ.get(\"API_GROQ\"))\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"} # pergunta realizada\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\", # modelo escolhido\n",
    "    temperature=0 # parametro para gerar respostas mais diretas e previsíveis\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a662149f-a04f-445b-a197-cb728cd4005d",
   "metadata": {},
   "source": [
    "# Criação da Classe Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e61e52-8b2d-49e5-bc6a-ec43bb3d88f6",
   "metadata": {},
   "source": [
    "Nesta parte do código, é criada manualmente a classe Agent, responsável por estruturar o agente de IA. Ela possui dois métodos especiais, \"__init__\" que inicializa o agente, definindo o cliente, mensagens e a instrução de sistema e o \"__call__\" permitindo que o agente seja chamado como uma função, registrando a entrada do usuário e retornando a resposta, além disso, há o método execute (não especial), que envia as mensagens para o modelo via API e retorna o conteúdo da resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4cb0d50-257f-48f6-8b2f-79382ff82671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None: # client será o groq e system será o prompt criado \n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = [] # historico de inputs e outputs do usuário e do modelo em suas intereções\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"): # junto ao metodo __init__ esses objetos formam a memória do modelo \n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message}) # adiciona as informações á lista de mensagens\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result}) # adiciona as informações á lista de mensagens\n",
    "        return result\n",
    "\n",
    "    def execute(self): # chamada ao modelo \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\", messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content # objeto que armazena a resposta do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f500187-6618-4150-a527-443404b06194",
   "metadata": {},
   "source": [
    "# Prompt e Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5771aab5-031f-409b-83fd-c73ed0bc2788",
   "metadata": {},
   "source": [
    "Nesta parte do código, é definido o system_prompt, que orienta o comportamento do agente durante a execução. O prompt descreve o ciclo de pensamento e ação no padrão de design react, lista as funções disponíveis e exemplifica como e quando utilizá-las, também são implementadas as ferramentas do agente:\n",
    "\n",
    "calculate: realiza operações matemáticas usando Python.\n",
    "\n",
    "get_planet_mass: retorna a massa de um planeta específico em quilogramas.\n",
    "\n",
    "Combinadas ao system_prompt e a uma estrutura de repetição, essas funções permitem que o agente responda de forma autônoma e personalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d07192-02fa-4089-8039-c7293b30c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def calculate(operation: str) -> float: # função de calculo\n",
    "    return eval(operation)\n",
    "\n",
    "\n",
    "def get_planet_mass(planet) -> float: # simula um banco de dados, armazenando os valores das massas dos planetas\n",
    "    match planet.lower():\n",
    "        case \"earth\":\n",
    "            return 5.972e24\n",
    "        case \"jupiter\":\n",
    "            return 1.898e27\n",
    "        case \"mars\":\n",
    "            return 6.39e23\n",
    "        case \"mercury\":\n",
    "            return 3.285e23\n",
    "        case \"neptune\":\n",
    "            return 1.024e26\n",
    "        case \"saturn\":\n",
    "            return 5.683e26\n",
    "        case \"uranus\":\n",
    "            return 8.681e25\n",
    "        case \"venus\":\n",
    "            return 4.867e24\n",
    "        case _:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7531ce-ed83-467a-908c-41c9a66fe6d8",
   "metadata": {},
   "source": [
    "# Instanciando o Agente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39c064e-bae8-4482-a06c-e67d552a8752",
   "metadata": {},
   "source": [
    "Nesta etapa, o agente é instanciado utilizando o client configurado anteriormente e o system_prompt definido nas células anteriores. Isso cria um objeto já preparado para executar interações seguindo as instruções e ferramentas especificadas no prompt orientador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59466ccb-af52-474c-955b-88c6274f5a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neil_tyson = Agent(client=client, system=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f48ca-51d1-4a87-abaf-e3bb0a4acee8",
   "metadata": {},
   "source": [
    "# Loop de repetição"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554bf262-8a0a-4bc8-a309-156d211fec33",
   "metadata": {},
   "source": [
    "Nesta parte, é criada a função loop, responsável por automatizar o raciocínio do modelo, a função recebe uma pergunta inicial e executa interações com o agente até atingir o número máximo definido por max_iterations, evitando loops infinitos, durante cada iteração, o resultado do agente é analisado e caso contenha uma ação com pausa, a função identifica a tool solicitada, executa-a e envia a observação resultante de volta ao agente, as etapas são exibidas no console para acompanhar o fluxo de execução atravez dos prints. \n",
    "\n",
    "Essa estrutura garante que o agente siga, de forma controlada, o ciclo Pensamento - Ação - PAUSA - Observação, utilizando as ferramentas necessárias (calculate e get_planet_mass)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e455198-db0e-4d8f-a5fb-407c9303d930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the masses of Earth and Saturn and then perform the required calculations.\n",
      "\n",
      "Action: get_planet_mass: Earth\n",
      "PAUSE\n",
      "Observation: 5.972e+24\n",
      "Thought: I have the mass of Earth, now I need to get the mass of Saturn.\n",
      "\n",
      "Action: get_planet_mass: Saturn\n",
      "PAUSE\n",
      "Observation: 5.683e+26\n",
      "Thought: I have the masses of Earth and Saturn. Now I need to add them together.\n",
      "\n",
      "Action: calculate: 5.972e24 + 5.683e26\n",
      "PAUSE\n",
      "Observation: 5.74272e+26\n",
      "Thought: I have the sum of the masses of Earth and Saturn. Now I need to multiply this by 2.\n",
      "\n",
      "Action: calculate: 5.74272e26 * 2\n",
      "PAUSE\n",
      "Observation: 1.148544e+27\n",
      "Thought: I have the final result.\n",
      "\n",
      "Answer: The mass of Earth plus the mass of Saturn and all of that times 2 is 1.148544e+27.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def loop(max_iterations=10, query: str = \"\"):\n",
    "\n",
    "    agent = Agent(client=client, system=system_prompt) # agente instanciado\n",
    "\n",
    "    tools = [\"calculate\", \"get_planet_mass\"] # lista de ferramentas\n",
    "\n",
    "    next_prompt = query # iniciar variavel next_prompt com entrada de usuário\n",
    "\n",
    "    i = 0 # contador de iterações\n",
    "  \n",
    "    while i < max_iterations: # inicio do loop, com limite de iterações = 10\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result) # Início de\n",
    "\n",
    "        if \"PAUSE\" in result and \"Action\" in result: # verificação da ação e pausa na resposta do modelo\n",
    "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE) # função regex para encontrar ferramenta e argumento\n",
    "            chosen_tool = action[0][0] # armazena ferramenta solicitada pelo modelo \n",
    "            arg = action[0][1] # rmazena o argumento passado para essa ferramenta\n",
    "\n",
    "            if chosen_tool in tools: # validação com a lista de ferramentas\n",
    "                result_tool = eval(f\"{chosen_tool}('{arg}')\") # interpreta a string como código e executa-a\n",
    "                next_prompt = f\"Observation: {result_tool}\" # informa ao modelo o resultado da ferramenta executada\n",
    "\n",
    "            else:\n",
    "                next_prompt = \"Observation: Tool not found\" # tratar erro caso não ncontre a ferramenta\n",
    "\n",
    "            print(next_prompt) # registra no \"log\"\n",
    "            continue\n",
    "\n",
    "        if \"Answer\" in result: # consição para quebrar o loop, caso a resposta seja gerada\n",
    "            break\n",
    "\n",
    "\n",
    "loop(query=\"What is the mass of Earth plus the mass of Saturn and all of that times 2?\") # função de loop iniciada com a query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
