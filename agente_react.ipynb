{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26e8f14d-6bfb-44f7-a900-d43f0b7570fb",
   "metadata": {},
   "source": [
    "# Definir client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bdc09e1-bbe3-402d-b318-0f49ca7939aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "API_KEY_GROQ = \"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\"\n",
    "client = Groq(api_key=API_KEY_GROQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77622dc9-3e06-49a1-85fc-40afaa5251f0",
   "metadata": {},
   "source": [
    "# Criar classe Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b711696-62d8-4f37-86c7-d5d568d816da",
   "metadata": {},
   "source": [
    "Esse codigo é responsável por definir a estrutura do nosso agente, facilitando a interação do modelo com as açoes que o rodeiam\n",
    "\n",
    "Ele é composto por tres funçoes:\n",
    "\n",
    "- __init__: recebe o client groq e o promt que orienta as ações que ele realizará\n",
    "\n",
    "- __call__: é um orquestrador de memória, sendo responsável por armazenar novas informações e manda-la ao agente para uso\n",
    "\n",
    "- __execute__: é o intermediário entre o client e o modelo, reponável por enviar a memória ao modelo \"llama-3.3-70b-versatile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9940147f-10d0-4306-a493-cd6f390fbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama-3.3-70b-versatile\", messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b4e749-bc69-4b87-bbdd-61f690b0da96",
   "metadata": {},
   "source": [
    "# Prompt Orientador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b2bfae-6350-4318-8be8-708229d75308",
   "metadata": {},
   "source": [
    "É nessa parte do script que está o cerebro do agente ReAct funcionando como o guia do agente.\n",
    "Nela, são definidas as orientações acerca das funções disponíveis, do fluxo de trabalho e da forma de raciocínio que o modelo deve seguir.\n",
    "Ela é composta por três partes principais:\n",
    "\n",
    "1. Introdução:\n",
    "Apresenta ao agente uma visão geral sobre sua função, explicando o que ele deve fazer e como fazer.\n",
    "\n",
    "2. Definição de Ferramentas (Tools):\n",
    "Lista, descreve e exemplifica todas as ações que o agente pode realizar, deixando claro quais ferramentas estão disponíveis e quando devem ser utilizadas.\n",
    "\n",
    "3. Fluxo de Trabalho:\n",
    "Mostra, por meio de um exemplo prático, como o agente deve agir em situações reais.\n",
    "Define padrões para entradas e saídas, orienta o comportamento esperado e exemplifica como aplicar as ferramentas para gerar respostas e executar ações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d7b8203-232e-4cd9-bb2d-4c1278e01760",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Você funciona em um ciclo de Pensamento, Ação, PAUSA, Observação.\n",
    "Ao final do ciclo, você gera uma Resposta.\n",
    "Use Pensamento para descrever seu raciocínio sobre a pergunta que recebeu.\n",
    "Use Ação para executar uma das ações disponíveis - então retorne com PAUSA.\n",
    "Observação será o resultado da ação realizada.\n",
    "\n",
    "Suas ações disponíveis são:\n",
    "\n",
    "consultar_tipos_bolo:\n",
    "ex: consultar_tipos_bolo: chocolate\n",
    "Retorna um objeto com preco_base_por_kg\n",
    "Formato: {\"nome\":\"chocolate\",\"preco_base_por_kg\":60}\n",
    "\n",
    "calcular:\n",
    "ex: calcular: 2 * 60\n",
    "Executa um cálculo e retorna o número.\n",
    "\n",
    "Pergunta: Qual é o valor de um bolo de chocolate de 2 quilos?\n",
    "\n",
    "Pensamento: Preciso listar os sabores necessários.\n",
    "Ação: consultar_tipos_bolo: chocolate\n",
    "PAUSA\n",
    "\n",
    "Você será chamado novamente com isso:\n",
    "\n",
    "Observação: {\"nome\":\"chocolate\", \"preco_base_por_kg\":60}\n",
    "\n",
    "Pensamento: Qual o valor de um bolo de 2 quilos?\n",
    "Ação: calcular: 2 * 60\n",
    "PAUSA\n",
    "\n",
    "Você será chamado novamente com isso:\n",
    "\n",
    "Observação: 120.0\n",
    "\n",
    "Se você já tiver a resposta, finalize com ela.\n",
    "\n",
    "Resposta: O valor de um bolo de chocolate de 2 quilos é de 120 reais\n",
    "\n",
    "Importante: forneça apenas **uma única resposta final** usando o formato \"Resposta: ...\". Evite repetir a resposta.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3b95fe-3929-41d0-adff-2d3d6b6b4376",
   "metadata": {},
   "source": [
    "# Dicionário básico para acesso de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dc38fa-dddf-4f5f-a9fc-b9822f64c05b",
   "metadata": {},
   "source": [
    "É apenas uma meneira simples de informar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5b5d29-28f8-49ca-80cd-dc723bfebc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLOS = [\n",
    "    {\"nome\": \"chocolate\",  \"preco_base_por_kg\": 60},\n",
    "    {\"nome\": \"baunilha\",   \"preco_base_por_kg\": 55},\n",
    "    {\"nome\": \"cenoura\",    \"preco_base_por_kg\": 58},\n",
    "    {\"nome\": \"red velvet\", \"preco_base_por_kg\": 68}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e007efbf-440a-44e4-a79d-670a54f7bb93",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db8daf-d5eb-42c5-ba49-ba61011d5081",
   "metadata": {},
   "source": [
    "Nessa sessão são definidas as tools para o agente\n",
    "\n",
    "- consultar_tipos_bolo: Faz uma verificação lógica, na qual se o nome do dicionário for igual ao nome escolhido pelo usuário ele retorna um dicionário com o nome e valor por quilo do bolo.\n",
    "\n",
    "- calcular: Avalia uma expressão matemática recebida e retorna o resultado como numero em formato float, usada pelo agente quando ele precisa realizar contas.\n",
    "\n",
    "- parse_action: O parse_action usa uma função de regex para identificar no texto do modelo qual ação foi solicitada e, a partir disso, converter essa instrução textual na chamada da função correspondente.\n",
    "\n",
    "- extract_thought: Serve para localizar e extrair o texto do bloco \"Pensamento:\" da resposta do modelo, isolando apenas o raciocínio que o agente escreveu antes de executar uma ação, dar a resposta ou pausar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e17534-5d2b-48d1-9336-56e020e5eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import math\n",
    "from typing import Dict, Tuple, Optional\n",
    "import re, json\n",
    "\n",
    "def consultar_tipos_bolo(sabor: str) -> Dict:\n",
    "    for item in BOLOS:\n",
    "        if item[\"nome\"].lower() == sabor.strip().lower():\n",
    "            return item\n",
    "    return {}\n",
    "\n",
    "def calcular(expr: str) -> float:\n",
    "    allowed_names = {k: getattr(math, k) for k in dir(math) if not k.startswith(\"_\")}\n",
    "    return float(eval(expr, {\"__builtins__\": {}}, allowed_names))\n",
    "\n",
    "def analisar_acao(texto: str):\n",
    "    m = re.search(r\"A(?:ção|cao)\\s*:\\s*([a-zA-Z_]+)\\s*:\\s*(.+)\", texto, flags=re.I)\n",
    "    if not m:\n",
    "        return None\n",
    "    return m.group(1).strip(), m.group(2).strip()\n",
    "\n",
    "def extrair_pensamento(texto: str):\n",
    "    m = re.search(r\"Pensamento\\s*:\\s*(.*?)(?:\\n(?:A(?:ção|cao)|Resposta|PAUSA)\\b|$)\",\n",
    "                  texto, flags=re.I|re.S)\n",
    "    return m.group(1).strip() if m else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7826a2a5-62e4-42cb-9190-42c074757025",
   "metadata": {},
   "source": [
    "# Função de Loop para iterar etapas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3592b5-2539-438e-aafa-918d21363969",
   "metadata": {},
   "source": [
    "Essa função loop serve para automatizar os processos definidos de realização de tarefas. Colocando em prática o ciclo Pensamento, Ação, PAUSA, Observação até a resposta gerada ser satisfatória.\n",
    "\n",
    "1) O loop começa recebendo a entrada do usuário (query) e definindo-a como próximo prompt a ser enviado ao modelo.\n",
    "2) Em seguida, entra em um ciclo que se repete até o número máximo de iterações permitido (neste caso, 10).\n",
    "3) Cada rodada envia o next_prompt ao modelo e analisa a resposta recebida.\n",
    "4) Primeiro tenta extrair o “Pensamento” para registrar o raciocínio.\n",
    "5) Verifica se há uma instrução de ação (Ação: ...) seguida de PAUSA; se houver, executa a ferramenta indicada com o argumento informado.\n",
    "6) Obtém o resultado (Observação) e prepara um novo prompt com esse valor para a próxima iteração.\n",
    "7) Se não houver ação, mas a resposta já tiver \"Resposta: ...\", extrai esse conteúdo e encerra o loop retornando o valor final.\n",
    "8) Caso contrário, define uma observação e segue para a próxima rodada, até que o modelo forneça a resposta ou o limite de iterações seja atingido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f27a9378-3251-4ce6-9829-c46d648f5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(query: str, envia_modelo, maximo_iteracoes: int = 10):\n",
    "    proximo_prompt = query\n",
    "\n",
    "    for i in range(1, maximo_iteracoes + 1):\n",
    "        print(f\"\\n====== Iteração {i} ======\")\n",
    "        print(f\"[→ Enviado ao modelo]\\n{proximo_prompt}\")\n",
    "\n",
    "        resp = envia_modelo(proximo_prompt)\n",
    "        print(f\"[← Saída do modelo]\\n{resp}\")\n",
    "        \n",
    "        pensamento = extrair_pensamento(resp)\n",
    "        if pensamento:\n",
    "            print(f\"[Pensamento] {pensamento}\")\n",
    "\n",
    "        analisado = analisar_acao(resp)\n",
    "        has_pausa = bool(re.search(r\"\\bPAUSA\\b\", resp, flags=re.I))\n",
    "        if analisado and has_pausa:\n",
    "            tool, arg = analisado\n",
    "            print(f\"[Ação] {tool}({arg})\")\n",
    "            print(\"[PAUSA] aguardando Observação...\")\n",
    "\n",
    "            if tool == \"consultar_tipos_bolo\":\n",
    "                obs = consultar_tipos_bolo(arg)\n",
    "            elif tool == \"calcular\":\n",
    "                obs = calcular(arg)\n",
    "            else:\n",
    "                obs = \"Ferramenta não encontrada\"\n",
    "\n",
    "            obs_text = json.dumps(obs, ensure_ascii=False) if isinstance(obs, (dict, list)) else str(obs)\n",
    "            print(f\"[Observação] {obs_text}\")\n",
    "\n",
    "            proximo_prompt = f\"Observação: {obs_text}\"\n",
    "            continue\n",
    "\n",
    "        m = re.search(r\"Resposta\\s*:\\s*(.+)\", resp, flags=re.I|re.S)\n",
    "        if m:\n",
    "            resposta_final = m.group(1).strip()\n",
    "            print(f\"[✅ Resposta final] {resposta_final}\")\n",
    "            return resposta_final\n",
    "\n",
    "        print(\"[Aviso] Não detectei Ação/PAUSA nem Resposta. Enviando observação neutra.\")\n",
    "        proximo_prompt = \"Observação: (nenhuma ação detectada)\"\n",
    "\n",
    "    return \"Não foi possível concluir em tempo.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53430e5-5929-4f3c-ad1c-3d24d6ae7b80",
   "metadata": {},
   "source": [
    "# Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24854b86-d604-44ce-b23b-e6ee641b6388",
   "metadata": {},
   "source": [
    "Esse trecho de código é o conector entre o agente e a API da Groq.",
    "Ele cria um cliente, mantém um histórico da conversa e define a função que envia mensagens ao modelo, retornando as respostas recebidas dele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e64f5f-fee7-45ca-b4db-0e4b1eaf7862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "API_KEY_GROQ = \"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\"\n",
    "client = Groq(api_key=API_KEY_GROQ)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt}\n",
    "]\n",
    "\n",
    "def envia_modelo(msg: str) -> str:\n",
    "    messages.append({\"role\": \"user\", \"content\": msg})\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    text = resp.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": text})\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49c60a58-88c2-4afc-b81f-f9179459f9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Iteração 1 ======\n",
      "[→ Enviado ao modelo]\n",
      "Qual é o valor de um bolo de baunilha de 4 quilos?\n",
      "[← Saída do modelo]\n",
      "Pensamento: Preciso saber o preço base por quilo do bolo de baunilha.\n",
      "Ação: consultar_tipos_bolo: baunilha\n",
      "PAUSA\n",
      "[Pensamento] Preciso saber o preço base por quilo do bolo de baunilha.\n",
      "[Ação] consultar_tipos_bolo(baunilha)\n",
      "[PAUSA] aguardando Observação...\n",
      "[Observação] {\"nome\": \"baunilha\", \"preco_base_por_kg\": 55}\n",
      "\n",
      "====== Iteração 2 ======\n",
      "[→ Enviado ao modelo]\n",
      "Observação: {\"nome\": \"baunilha\", \"preco_base_por_kg\": 55}\n",
      "[← Saída do modelo]\n",
      "Pensamento: Agora que tenho o preço base por quilo, posso calcular o valor total do bolo de 4 quilos.\n",
      "Ação: calcular: 4 * 55\n",
      "PAUSA\n",
      "[Pensamento] Agora que tenho o preço base por quilo, posso calcular o valor total do bolo de 4 quilos.\n",
      "[Ação] calcular(4 * 55)\n",
      "[PAUSA] aguardando Observação...\n",
      "[Observação] 220.0\n",
      "\n",
      "====== Iteração 3 ======\n",
      "[→ Enviado ao modelo]\n",
      "Observação: 220.0\n",
      "[← Saída do modelo]\n",
      "Resposta: O valor de um bolo de baunilha de 4 quilos é de 220 reais\n",
      "[✅ Resposta final] O valor de um bolo de baunilha de 4 quilos é de 220 reais\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'O valor de um bolo de baunilha de 4 quilos é de 220 reais'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop(\"Qual é o valor de um bolo de baunilha de 4 quilos?\", envia_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9021fbb-b101-42ff-958f-70bc15dd8501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
